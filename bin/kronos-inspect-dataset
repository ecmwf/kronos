#!/usr/bin/env python
# (C) Copyright 1996-2017 ECMWF.
#
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.
# In applying this licence, ECMWF does not waive the privileges and immunities
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""

============================================================================
       **DEVELOPMENT TOOL** - USAGE OF THIS TOOL IS UNSUPPORTED
============================================================================

Show summary of information contained into a Kronos dataset

"""

import os
import argparse

import sys
from kronos.core.logreader.dataset import IngestedDataSet

if __name__ == "__main__":

    # Parser for the required arguments
    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("path", type=str, help="Path of pickeld ingested datasets (file or directory)")
    parser.add_argument("--mode", type=str, help="Export mode", choices=["per_job_summary", "time_series"], default="per_job_summary")
    parser.add_argument("--param", type=str, help="Name of the parameter to export (only used if mode=time_series")

    # print the help if no arguments are passed
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    # parse the arguments..
    args = parser.parse_args()

    try:
        assert os.path.exists(args.path)
    except AssertionError:
        raise AssertionError("ERROR: Specified path does not exist: {}".format(args.path))

    # Collect the dataset (either from folder or path)
    if os.path.isfile(args.path):
        dataset = IngestedDataSet.from_pickled(args.path)
    else:
        pickle_files = os.listdir(args.path)
        datasets = [IngestedDataSet.from_pickled(os.path.join(args.path, pk)) for pk in pickle_files]
        assert (all(type(x) == type(datasets[0]) for x in datasets))
        dataset_type = type(datasets[0])
        dataset = dataset_type([job for d in datasets for job in d.joblist], "", "")

    if args.mode == "per_job_summary":
        for jj, job in enumerate(dataset.joblist):

            _h, _f = job.summary_report()

            # print header only at the beginning
            if not jj:
                print _h

            # print fields
            print _f

    # "time_series" means asking for the series of the specified param for the whole dataset
    elif args.mode == "time_series":
        print "\n".join(["[ts]: {}: {}".format(t, v) for t, v in dataset.export_time_series(args.param)])
