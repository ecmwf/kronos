#!/usr/bin/env python
# (C) Copyright 1996-2017 ECMWF.
#
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.
# In applying this licence, ECMWF does not waive the privileges and immunities
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""

Script that checks if Kronos has executed a specific metrics as prescribed by the KSchedule file.
It loops over the job output folders, it sums all the values of the selected metric found
in the .KResults files and compares the sum with the sum retrieved from the KSchedule file
(the test is considered PASS if the difference is < 1%)

"""

import argparse
import json
import os
import sys

from kronos.io.format_data_handlers.kresults_job import KResultsJob
from kronos.core.time_signal.definitions import signal_types, time_signal_names
from kronos.io.format_data_handlers.kresults_decorator import KResultsDecorator
from kronos.io.schedule_format import ScheduleFormat


def cumsum(input_list):
    return [sum(input_list[:ii+1]) for ii,i in enumerate(input_list)]


if __name__ == "__main__":

    # Parser for the required arguments
    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("job_dir", type=str, help="Path of the kronos output folder 'job_dir' (contains the job-<ID> sub-folders)")
    parser.add_argument("metrics", choices=signal_types.keys()+["all"], nargs='+')

    # print the help if no arguments are passed
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    # parse the arguments..
    args = parser.parse_args()

    # check that the run path exists
    if not os.path.exists(args.job_dir):
        print "Specified run path does not exist: {}".format(args.job_dir)
        sys.exit(1)

    # check that the run path contains the job sub-folders
    job_dirs = [x for x in os.listdir(args.job_dir) if os.path.isdir(os.path.join(args.job_dir, x)) and "job-" in x]
    if not job_dirs:
        print "Specified path does not contain any job folder (<job-ID>..)!"
        sys.exit(1)

    # check that the run path contains the kschedule file
    kschedule_file = [x for x in os.listdir(args.job_dir) if os.path.isfile(os.path.join(args.job_dir, x)) and x.endswith('.kschedule')]
    if not kschedule_file:
        print "Specified path does not contain the KSchedule file!"
        sys.exit(1)

    if len(kschedule_file) > 1:
        print "Specified path contains more than one KSchedule file!"
        sys.exit(1)

    # Loop over all sub-folders
    kresult_jobs = []
    for job_subdir in job_dirs:

        # read the statistics.kresults file
        kresults_file_path_abs = os.path.join(os.path.join(args.job_dir, job_subdir), "statistics.kresults")
        if not os.path.isfile(kresults_file_path_abs):
            sys.exit(1)

        # read the corresponding json of the input and read the label
        input_file_path_abs = os.path.join(os.path.join(args.job_dir, job_subdir), 'input.json')
        with open(input_file_path_abs, 'r') as f:
            input_data_json = json.load(f)
        input_job_label = input_data_json.get("metadata", {}).get("workload_name")
        input_job_name = input_data_json.get("metadata", {}).get("job_name")

        kresult_decorator = KResultsDecorator(workload_name=input_job_label, job_name=input_job_name)
        kresult_job_data = KResultsJob.from_kresults_file(kresults_file_path_abs, decorator=kresult_decorator)
        kresult_jobs.append(kresult_job_data)

    # read data from the KSchedule
    kschedule_data = ScheduleFormat.from_filename(os.path.join(args.job_dir, kschedule_file[0]))
    tot_kschedule_metrics = {k: signal_types[k]["type"](0) for k in time_signal_names}

    for synth_app in kschedule_data.synapp_data:
        for frame in synth_app["frames"]:

            for ker in frame:

                if ker["name"] == "cpu":
                    tot_kschedule_metrics["flops"] += signal_types["flops"]["type"](ker["flops"])

                elif ker["name"] == "file-read":
                    tot_kschedule_metrics["kb_read"] += signal_types["kb_read"]["type"](ker["kb_read"])
                    tot_kschedule_metrics["n_read"] += signal_types["n_read"]["type"](ker["n_read"])

                elif ker["name"] == "file-write":
                    tot_kschedule_metrics["kb_write"] += signal_types["kb_write"]["type"](ker["kb_write"])
                    tot_kschedule_metrics["n_write"] += signal_types["n_write"]["type"](ker["n_write"])

                elif ker["name"] == "mpi":
                    tot_kschedule_metrics["n_pairwise"] += signal_types["n_pairwise"]["type"](ker["n_pairwise"])
                    tot_kschedule_metrics["kb_pairwise"] += signal_types["kb_pairwise"]["type"](ker["kb_pairwise"])
                    tot_kschedule_metrics["n_collective"] += signal_types["n_collective"]["type"](ker["n_collective"])
                    tot_kschedule_metrics["kb_collective"] += signal_types["kb_collective"]["type"](ker["kb_collective"])

                # ------------ additional kernels --------
                elif ker["name"] == "fs_metadata":
                    tot_kschedule_metrics["n_mkdir"] += int(ker["n_mkdir"])
                else:
                    raise ("kernel name {} not recognized!".format(ker["name"]))

    # get the full list of metrics to test (considering the all case)
    metrics_to_test = [user_metric for user_metric in args.metrics if user_metric.lower() != "all"]
    if "all" in args.metrics:
        metrics_to_test += signal_types.keys()

    # check all the metrics selected
    failed_checks = []
    for metric_name in metrics_to_test:
        metric_sum_kresults = sum([v if v else 0 for j in kresult_jobs for v in j.time_series.get(metric_name, {}).get("values", [0])])
        metric_sum_kschedule = tot_kschedule_metrics[metric_name]

        # Accumulate the errors

        # if there is no such operation in the ksf, a sum=0 is expected
        if not abs(metric_sum_kschedule):
            if metric_sum_kresults:
                _err = "ERROR: {}: measured {} not equal to total value in KSchedule {}".format(metric_name,
                                                                                                metric_sum_kresults,
                                                                                                metric_sum_kschedule)
                failed_checks.append(_err)

        else:  # else, check the relative error..
            if abs(metric_sum_kresults-metric_sum_kschedule)/abs(metric_sum_kschedule) > 0.01:
                _err = "ERROR: {}: measured {} and total value in KSchedule {} differ for more than 1%".format(metric_name,
                                                                                                               metric_sum_kresults,
                                                                                                               metric_sum_kschedule)
                failed_checks.append(_err)

    # if some checks have failed, list them and exit else report success
    if failed_checks:
        for err in failed_checks:
            print err
        sys.exit(1)
    else:
        sys.exit(0)
