#!/usr/bin/env python2.7
# (C) Copyright 1996-2017 ECMWF.
# 
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0. 
# In applying this licence, ECMWF does not waive the privileges and immunities 
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""
Kronos tool to quickly inspect the results of a run
"""

import argparse
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.pyplot import cm

from kronos.core.kronos_tools.utils import bin_array, running_series, calculate_signals_similarity
from kronos.core.time_signal import time_signal_names
from kronos.core.plot_handler import PlotHandler
from kronos.core.workload_data import WorkloadData, WorkloadDataGroup
from kronos.io.profile_format import ProfileFormat


def make_plots(info_model, info_orig):

    plt_hdl = PlotHandler()
    color = iter(cm.rainbow(np.linspace(0, 1, len(wl_model_group.tags))))
    plt.figure(plt_hdl.get_fig_handle_ID(), figsize=(18, 8))

    for lbl_i, lbl in enumerate(wl_model_group.tags):

        line_color = next(color)

        plt.subplot(2, 1, 1)
        plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)
        plt.plot(info_model[lbl]["times_relative_model"],
                 info_model[lbl]["running_model_norm"],
                 color=line_color, linestyle='-', label=lbl)
        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
        plt.ylabel('#jobs/Njobs (model)')
        plt.xlabel('time [s]')
        plt.title('#jobs/Njobs (n_bins={} [s])'.format(n_bins))

        plt.subplot(2, 1, 2)
        plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)
        plt.plot(info_orig[lbl]["times_relative_orig"],
                 info_orig[lbl]["running_orig_norm"],
                 color=line_color, linestyle='-')
        plt.ylabel('#jobs/Njobs (original)')
        plt.xlabel('time [s]')

    plt.savefig('n_jobs.png')
    plt.close()

    # plots of the total time-signals
    for ts_i, ts in enumerate(time_signal_names):

        plt_hdl = PlotHandler()
        color = iter(cm.rainbow(np.linspace(0, 1, len(wl_model_group.tags))))
        plt.figure(plt_hdl.get_fig_handle_ID(), figsize=(18, 8))

        for lbl_i, lbl in enumerate(wl_model_group.tags):

            line_color = next(color)

            plt.subplot(2, 1, 1)
            plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)
            if info_model[lbl]["total_metrics"].get(ts):
                plt.plot(info_model[lbl][ts]["times_relative_model"],
                         info_model[lbl][ts]["binned_vals_model"],
                         color=line_color, label=lbl)
            plt.ylabel(ts + " - model")
            plt.xlabel('time [s]')
            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))

            plt.subplot(2, 1, 2)
            plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)
            if info_orig[lbl]["total_metrics"].get(ts):
                plt.plot(info_orig[lbl][ts]["times_relative_orig"],
                         info_orig[lbl][ts]["binned_vals_orig"],
                         color=line_color, label=lbl)
            plt.ylabel(ts + " - original")
            plt.xlabel('time [s]')

        plt.savefig(ts + '.png')
        plt.close()


def calc_error(info_model, info_orig, n_jobs_error):

    # print summary
    _fl = 25

    print "\nRUN SUMMARY\n"
    print "{}".format("-" * (_fl + 1) * 4)
    print "{:^{l}}{:^{l}}{:^{l}}{:^{l}}".format("name", "sum model", "sum orig", "sum relative", l=_fl)
    print "{}".format("-" * (_fl + 1) * 4)

    for ts_name in ts_sums_model.keys():
        print "{:<{l}};{:>{l}.2f};{:>{l}.2f};{:>{l}.5f}".format(ts_name,
                                                                ts_sums_model[ts_name],
                                                                ts_sums_orig[ts_name],
                                                                ts_sums_model[ts_name] / ts_sums_orig[ts_name],
                                                                l=_fl)

    # plots of the total time-signals
    for ll, label in enumerate(wl_model_group.tags):

        print "\n{}".format("-" * (_fl + 1) * 3)
        print "{:^{l}s}|".format("WORKLOAD: " + label.upper(), l=(_fl + 1) * 3 - 1)
        print "{}".format("-" * (_fl + 1) * 3)
        print "{:^{l}s}|{:^{l}s}|{:^{l}s}|".format("Quantity",
                                                   "relative time error [%]",
                                                   "relative corr err [%]",
                                                   l=_fl)
        print "{}".format("-" * (_fl + 1) * 3)

        # print also the error on the number of jobs..
        print "{:<{l}s}|{:>{l}.1f}|{:>{l}.1f}|".format("N running-jobs", n_jobs_error[label][0],
                                                       n_jobs_error[label][1],
                                                       l=_fl)

        for tt, ts_name in enumerate(time_signal_names):

            # calculate metrics relative offset
            if info_model[label]["total_metrics"].get(ts_name) and info_orig[label]["total_metrics"].get(ts_name):
                metrics_error = calculate_signals_similarity(info_model[label][ts_name]["times_relative_model"],
                                                             info_model[label][ts_name]["binned_vals_model"],
                                                             info_orig[label][ts_name]["times_relative_orig"],
                                                             info_orig[label][ts_name]["binned_vals_orig"])

                print "{:<{l}s}|{:>{l}.1f}|{:>{l}.1f}|".format(ts_name, metrics_error[0], metrics_error[1], l=_fl)
            else:

                # print relative time offset..
                print "{:<{l}s}|{:>{l}s}|{:>{l}s}|".format(ts_name, "N/A", "N/A", l=_fl)
        print "{}\n".format("-" * (_fl + 1) * 3)


if __name__ == "__main__":

    # Parser for the required arguments
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("path_model_kpf", type=str, help="Path of the KPF file to read")
    parser.add_argument("path_unmodelled_pickle", help="Path of pickle file of un-modelled data to over-plot")
    parser.add_argument("--nbins", "-n", help="duration [sec] of each bin used to discretise the time series")
    parser.add_argument("--plot", "-p", help="make model vs original comparison plots", action="store_true")
    parser.add_argument("--error", "-e", help="calculate error model vs original workload", action="store_true")

    args = parser.parse_args()

    # take n_bins or use a default value
    n_bins = float(args.nbins) if args.nbins else 100.0

    # retrieve kpf data from model run
    kpf_workload = WorkloadData.from_kpf(ProfileFormat.from_filename(args.path_model_kpf))
    n_apps = len(kpf_workload.jobs)
    wl_model_group = kpf_workload.group_by_job_labels
    t0_model = wl_model_group.min_start_time
    tend_model = wl_model_group.max_end_time
    ts_sums_model = wl_model_group.sum_timeseries
    t_bins_model = np.linspace(t0_model, tend_model, n_bins + 1)
    t_model_all = (t_bins_model[:-1] + t_bins_model[1:]) / 2.0
    n_jobs_in_group_model = wl_model_group.sum_jobs

    # retrieve information from KPF of original workloads
    wl_orig_group = WorkloadDataGroup.from_pickled(args.path_unmodelled_pickle)
    t0_orig = wl_orig_group.min_start_time
    tend_orig = wl_orig_group.max_end_time
    ts_sums_orig = wl_orig_group.sum_timeseries
    t_bins_orig = np.linspace(t0_orig, tend_orig, n_bins + 1)
    t_orig_all = (t_bins_orig[:-1] + t_bins_orig[1:]) / 2.0
    n_jobs_in_group_orig = wl_orig_group.sum_jobs

    # ----------- collect all the info before plotting for efficiency reasons.. ---------------
    global_info_model = {}
    global_info_orig = {}
    global_n_jobs_error = {}
    for ll, label in enumerate(wl_model_group.tags):

        # --------- retrieve kpf data from iteration -------------
        kpf_workload = wl_model_group.get_workload_by_name(label)
        total_metrics_model = kpf_workload.total_metrics_timesignals

        times_relative_model = t_model_all - t_model_all[0]
        running_model = running_series(wl_model_group.get_workload_by_name(label).jobs, t_model_all)
        running_model_norm = running_model / float(n_jobs_in_group_model)

        global_info_model[label] = {
            "total_metrics": total_metrics_model,
            "times_relative_model": times_relative_model,
            "running_model_norm": running_model_norm,
        }

        # --------------------------------------------------------

        # ------- retrieve jobs fro the original workload.. ------
        kpf_workload_orig = wl_orig_group.get_workload_by_name(label)
        total_metrics_original = kpf_workload_orig.total_metrics_timesignals

        times_relative_orig = t_orig_all - t_orig_all[0]
        running_orig = running_series(wl_orig_group.get_workload_by_name(label).jobs, t_orig_all)
        running_orig_norm = running_orig / float(n_jobs_in_group_orig)

        global_info_orig[label] = {
            "total_metrics": total_metrics_original,
            "times_relative_orig": times_relative_orig,
            "running_orig_norm": running_orig_norm,
        }
        # --------------------------------------------------------

        # --- append the relative offset by cross-correlation of the n jobs signals ---
        global_n_jobs_error[label] = calculate_signals_similarity(times_relative_model,
                                                                  running_model_norm,
                                                                  times_relative_orig,
                                                                  running_orig_norm)

        # ------ now extract metrics grouped per time series..
        for tt, ts_name in enumerate(time_signal_names):

            total_metrics_model_ts = total_metrics_model.get(ts_name)
            total_metrics_original_ts = total_metrics_original.get(ts_name)

            # model
            if global_info_model[label]["total_metrics"].get(ts_name):
                y_vals_norm_model = total_metrics_model_ts.yvalues / ts_sums_model[ts_name]
                times_plot_model, binned_vals_model = bin_array(total_metrics_model_ts.xvalues, y_vals_norm_model, t_bins_model, mode="sum")
                times_relative_model = times_plot_model - times_plot_model[0]

                global_info_model[label][ts_name] = {
                    "times_relative_model": times_relative_model,
                    "binned_vals_model": binned_vals_model,
                }

            # orig
            if global_info_orig[label]["total_metrics"].get(ts_name):
                y_vals_norm_orig = total_metrics_original_ts.yvalues / ts_sums_orig[ts_name]
                times_plot_orig, binned_vals_orig = bin_array(total_metrics_original_ts.xvalues, y_vals_norm_orig, t_bins_orig, mode="sum")
                times_relative_orig = times_plot_orig - times_plot_orig[0]

                global_info_orig[label][ts_name] = {
                    "times_relative_orig": times_relative_orig,
                    "binned_vals_orig": binned_vals_orig,
                }

    if args.plot:
        make_plots(global_info_model, global_info_orig)

    if args.error:
        calc_error(global_info_model, global_info_orig, global_n_jobs_error)
