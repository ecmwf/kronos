#!/usr/bin/env python
# (C) Copyright 1996-2018 ECMWF.
# 
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0. 
# In applying this licence, ECMWF does not waive the privileges and immunities 
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""

Tool to generate a simple workload for testing purposes only.
It can be used to preliminary-test modelling algorithms.

"""

import sys
import copy
import argparse

try:
    import cPickle as pickle
except ImportError:
    import pickle

import numpy as np
from datetime import date

from kronos.core.time_signal.time_signal import TimeSignal
from kronos.core.time_signal.definitions import time_signal_names

from kronos.core.jobs import ModelJob
from kronos.io.profile_format import ProfileFormat


class UserGeneratedJob(object):
    """
    A user-generated job (mainly a name and a dictionary
    of generated timesignals)
    """

    # default values of n_proc and n_nodes
    n_procs = 1
    n_nodes = 1

    def __init__(self, name=None, timesignals=None, ts_scales=None):

        self.name = name
        self.timesignals = timesignals if timesignals else {}
        self.ts_scales = ts_scales if ts_scales else {}

        # scaleup factors
        scale_up_factors = {ts_name: 1.0 for ts_name in time_signal_names}
        scale_up_factors.update(ts_scales)

    def add_timesignal(self, timesignal):
        """
        Append another timesignal to the job
        :param timesignal:
        :return:
        """
        self.timesignals.update({timesignal.name: timesignal})

    @staticmethod
    def proto_signals(ts_len=5):
        """
        Return prototype signals
        :param ts_len:
        :return:
        """

        # prototype signals to chose from.
        # Each time-signal will stem from one of the
        # prototype signals of this list
        return [

            # sin with 5 full cycles
            np.abs(np.sin(np.linspace(0, 5 * 2 * np.pi, ts_len))),

            # cos with 3 full cycles
            np.abs(np.cos(np.linspace(0, 3 * 2 * np.pi, ts_len))),

            # central "dirac"-type of signal
            np.asarray([val if ts_len/3 < val < 2*ts_len/3 else 0. for val in range(ts_len)])

        ]

    @staticmethod
    def from_random_proto_signals(job_name=None, seed=0, ts_scales=None, ts_len=10):
        """
        Generate a job from randomly chosen signals (from signal prototypes..)
        :param job_name:
        :param seed:
        :param ts_scales:
        :param ts_len:
        :return:
        """

        ts_scales = ts_scales if ts_scales else {}

        np.random.seed(seed)

        proto_signals = UserGeneratedJob.proto_signals(ts_len=ts_len)

        timesignals = {}
        for ts_name in time_signal_names:

            xvalues = np.arange(ts_len)

            # toss a coin to decide which signal type to choose
            proto_signal_idx = np.random.randint(len(proto_signals))
            yvalues = np.asarray(proto_signals[proto_signal_idx])

            if ts_scales:
                yvalues = yvalues * ts_scales[ts_name]

            timesignals[ts_name] = TimeSignal.from_values(ts_name,
                                                          xvalues,
                                                          yvalues,
                                                          priority=10)

        return UserGeneratedJob(name=job_name,
                                timesignals=timesignals,
                                ts_scales=ts_scales)

    def max_duration(self):
        """
        Max signal duration
        :return:
        """

        return max([max(tsv.xvalues) for tsk, tsv in self.timesignals.iteritems()])

    def model_job(self):
        """
        Return a model job from this job
        :return:
        """

        return ModelJob(
            time_start=0,
            duration=self.max_duration(),
            ncpus=self.n_procs,
            nnodes=self.n_nodes,
            timesignals=self.timesignals,
            label=self.name
        )


class UserGeneratedJobSet(object):
    """
    A Set of usergeneratedjobs, it coordinates the generation
    of UserGeneratedJobs (e.g. from a few prototype jobs)
    """

    def __init__(self, jobs=None, job_labels=None):

        # the core jobs
        self.jobs = jobs

        # in case the jobs are labelled..
        self.job_labels = job_labels

    @staticmethod
    def from_prototype_jobs(proto_jobs, n_jobs=1, seed=0):

        # seed the random module
        np.random.seed(seed)

        # randomly choose a proto job and copy from it
        generated_jobs = []
        job_labels = []
        for job in range(n_jobs):
            proto_job_idx = np.random.randint(len(proto_jobs))

            job_labels.append(proto_job_idx)
            generated_jobs.append(copy.deepcopy(proto_jobs[proto_job_idx]))

        return UserGeneratedJobSet(jobs=generated_jobs,
                                   job_labels=job_labels)

    def model_jobs(self):
        """
        Returns model jobs
        :return:
        """

        for job in self.jobs:
            yield job.model_job()


def kprofile_generator(user_args, scale_ups=None):
    """
    Generates the jobs of the KProfile to be written out
    :param user_args:
    :param scale_ups:
    :return:
    """

    # factors to "scale up" each generated job..
    scale_up_factors = {ts_name: 1.0 for ts_name in time_signal_names}

    if scale_ups:
        scale_up_factors.update(scale_ups)

    # 1. First, randomly generate the proto-jobs from proto-signals
    proto_jobs = []
    for job_id in range(user_args.n_proto_jobs):
        user_job = UserGeneratedJob.from_random_proto_signals(job_name="job-{}".format(job_id),
                                                              seed=job_id,
                                                              ts_len=user_args.ts_len)
        proto_jobs.append(user_job)

    print "{} proto jobs generated!".format(len(proto_jobs))

    # 2. Then, generate all the other jobs spawn from the proto-jobs
    job_set = UserGeneratedJobSet.from_prototype_jobs(proto_jobs=proto_jobs,
                                                      n_jobs=user_args.n_jobs)

    print "{} jobs generated!".format(len(job_set.jobs))
    # ----------------------------------------------------------------

    return proto_jobs, job_set


def write_job_class_labels(file_output_name, labels_vec):
    """
    Write file class labels to output file
    :param file_output_name:
    :param labels_vec:
    :return:
    """

    # In addition to the KProfile also writes other two files with the indices and
    # prototypical classes from which the jobs have been generated
    with open(file_output_name, "w") as f:
        f.write("\n".join([str(l) for l in labels_vec]))


def write_job_prototype_classes(file_output_name, model_job_classes):
    """
    Write job class prototypes to output file
    :param file_output_name:
    :param model_job_classes:
    :return:
    """

    # Write out the prototype classes of the jobs into a csv file (for validation purposes..)
    with open(file_output_name, "w") as f:
        # header row
        f.write(" ".join(["{}-{}".format(ts, str(val))
                          for ts in time_signal_names
                          for val in range(args.ts_len)]))

        f.write("\n")

        # entry
        f.write("\n".join([
            " ".join([str(val)
                      for tsk, tsv in ts_proto_class.timesignals.iteritems()
                      for val in tsv.yvalues])
            for ts_proto_class in model_job_classes]))


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description=__doc__,
                                     formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument("krpofile_output_name", help="Name of generated .KProfile file")

    parser.add_argument("--scale",
                        help="Scaling factor of the time signals",
                        type=float)

    parser.add_argument("--ts_len",
                        help="Length of the time signals",
                        default=10, type=int)

    parser.add_argument("--n_proto_jobs",
                        help="N prototypical jobs from which all the other jobs are spawn",
                        default=3, type=int)

    parser.add_argument("--n_jobs", help="N of jobs to generate from the job prototypes",
                        default=10, type=int)

    # print the help if no arguments are passed
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    # parse the arguments..
    args = parser.parse_args()

    # make sure that the final extension is .kprofile
    if args.krpofile_output_name.split(".")[-1] != "kprofile":
        args.krpofile_output_name += ".kprofile"

    scale_up_factors = {
        "kb_collective": 1.0e3,
        "n_collective": 1.0e3,
        "kb_write": 1.0e3,
        "n_pairwise": 1.0e3,
        "n_write": 1.0e3,
        "n_read": 1.0e3,
        "kb_read": 1.0e3,
        "flops": 1.0e10,
        "kb_pairwise": 1.0e3
    }

    # generate the jobs
    proto_jobs, job_set = kprofile_generator(args, scale_ups=scale_up_factors)

    # generate a kprofile from these model jobs..
    kprofile_handle = ProfileFormat(uid=None,
                                    model_jobs=job_set.model_jobs(),
                                    created=date.today(),
                                    workload_tag="user_defined_workload")

    # write out the generated kprofile file
    kprofile_handle.write_filename(args.krpofile_output_name, indent=4)

    # write job class labels to output file
    write_job_class_labels(args.krpofile_output_name + ".job_labels", job_set.job_labels)

    # write job prototype classes file output
    write_job_prototype_classes(args.krpofile_output_name + ".job_classes", proto_jobs)
