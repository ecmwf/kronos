#!/usr/bin/env python
# (C) Copyright 1996-2018 ECMWF.
# 
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0. 
# In applying this licence, ECMWF does not waive the privileges and immunities 
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""

Tool to generate a simple workload for testing purposes only.
It can be used to preliminary-test modelling algorithms.

It works by generating a set of jobs, each job being spawn from a set of prototype jobs.
The prototype jobs are generated from time signals (time signals are generated
from a set of prototype time signals.

"""

import argparse
import sys

from kronos.shared_tools.user_generated_jobs import UserGeneratedJob
from kronos.shared_tools.user_generated_jobs import UserGeneratedJobSet
from kronos.shared_tools.user_generated_jobs import write_job_prototype_classes

try:
    import cPickle as pickle
except ImportError:
    import pickle

from datetime import date
from kronos.core.time_signal.definitions import time_signal_names
from kronos.io.profile_format import ProfileFormat


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description=__doc__,
                                     formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument("krpofile_output_name", help="Name of generated .KProfile file")

    parser.add_argument("--scale",
                        help="Scaling factor of the time signals",
                        type=float)

    parser.add_argument("--ts_len",
                        help="Length of the time signals",
                        default=10, type=int)

    parser.add_argument("--n_proto_jobs",
                        help="N prototypical jobs from which all the other jobs are spawn",
                        default=3, type=int)

    parser.add_argument("--n_jobs", help="N of jobs to generate from the job prototypes",
                        default=10, type=int)

    parser.add_argument("--write_input", help="N of jobs to generate from the job prototypes",
                        action="store_true")

    parser.add_argument("--ts_prob", help="Probability of a ts signal to be found in a job [0,1]",
                        default=1.0, type=float)

    # print the help if no arguments are passed
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    # parse the arguments..
    args = parser.parse_args()

    # make sure that the final extension is .kprofile
    if args.krpofile_output_name.split(".")[-1] != "kprofile":
        args.krpofile_output_name += ".kprofile"

    scale_up_factors = {
        "kb_collective": 1.0e3,
        "n_collective": 1.0e3,
        "kb_write": 1.0e3,
        "n_pairwise": 1.0e3,
        "n_write": 1.0e3,
        "n_read": 1.0e3,
        "kb_read": 1.0e3,
        "flops": 1.0e10,
        "kb_pairwise": 1.0e3
    }

    # factors to "scale up" each generated job..
    scale_up_factors = {ts_name: 1.0 for ts_name in time_signal_names}

    if args.scale:
        scale_up_factors.update(scale_up_factors)

    # 1. First, randomly generate the proto-jobs from proto-signals
    proto_jobs = []
    for job_id in range(args.n_proto_jobs):
        user_job = UserGeneratedJob.from_random_proto_signals(job_name="job-{}".format(job_id),
                                                              seed=job_id,
                                                              ts_len=args.ts_len)
        proto_jobs.append(user_job)

    print "{} prototype jobs generated!".format(len(proto_jobs))

    # 2. Then, generate all the other jobs spawn from the proto-jobs
    job_set = UserGeneratedJobSet.from_prototype_jobs(proto_jobs=proto_jobs,
                                                      n_jobs=args.n_jobs,
                                                      ts_probability=args.ts_prob)

    print "{} jobs generated!".format(len(job_set.jobs))
    # ----------------------------------------------------------------

    # generate a kprofile from these model jobs..
    kprofile_handle = ProfileFormat(uid=None,
                                    model_jobs=job_set.model_jobs(),
                                    created=date.today(),
                                    workload_tag="user_defined_workload")

    # write out the generated kprofile file
    kprofile_handle.write_filename(args.krpofile_output_name, indent=4)

    # write job class labels to output file
    job_set.write_job_class_labels(args.krpofile_output_name + ".job_labels")

    # write job prototype classes file output
    write_job_prototype_classes(args.krpofile_output_name + ".job_classes", proto_jobs)

    if args.write_input:
        job_set.write_input_matrix_to_file(args.krpofile_output_name + ".job_input")
