#!/usr/bin/env python
# (C) Copyright 1996-2017 ECMWF.
#
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.
# In applying this licence, ECMWF does not waive the privileges and immunities
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""

=====================================================================
Utility to go through the kronos run folder and generates a KPF file
from the statistics.krf files
=====================================================================

"""

import os
import json
import argparse
import numpy as np
import sys

from kronos.io.profile_format import ProfileFormat
from kronos.io.results_format import ResultsFormat

ts_names_map = {
    "n_write": ("n_write", 1.0),
    "n_read": ("n_read", 1.0),
    "bytes_write": ("kb_write", 1.0/1024.0),
    "bytes_read": ("kb_read", 1.0/1024.0),
    "n_pairwise": ("n_pairwise", 1.0),
    "bytes_pairwise": ("kb_pairwise", 1.0/1024.0),
    "n_collective": ("n_collective", 1.0),
    "bytes_collective": ("kb_collective", 1.0/1024.0),
    "flops": ("flops", 1.0),
}


def krf_to_profiled_job_json(krf_json, input_json):
    """
    Function that reads statistics.krf and input.json and builds job json data (to be later used for ProfileFormat)
    :param krf_json:
    :param input_json:
    :return:
    """

    job = {}

    # create time series json data from statistics.krf
    time_series_json = {}

    for rank_data in krf_json["ranks"]:

        tends = np.cumsum(rank_data["time_series"]['durations'])

        if not rank_data["time_series"]['durations']:
            # in case the durations are empty!
            return None

        for ts_name, ts_vals in rank_data["time_series"].iteritems():

            if ts_name != "durations":
                time_series_json.setdefault(ts_name, []).extend(zip(tends, ts_vals))

    # sort the time-series
    for ts in time_series_json.values():
        ts.sort(key=lambda _x: _x[0])

    # time delay of job submission
    if input_json.get("start_delay"):
        job['time_start'] = input_json.get("start_delay")

    # job runtime
    job['duration'] = max([v[0] for ts in time_series_json.values() for v in ts])

    if input_json.get("start_delay"):
        job['ncpus'] = input_json.get("num_procs")

    if input_json.get("metadata"):
        job['label'] = input_json["metadata"]["workload_name"]

    if input_json.get("metadata"):
        job['job_name'] = input_json["metadata"]["job_name"]

    # Append any time series data that is present
    time_series = {}
    for name, values in time_series_json.iteritems():

        # assert name in time_signal.signal_types
        assert name in ts_names_map.keys()

        if values is not None:
            time_series[ts_names_map[name][0]] = {
                'times': list(zip(*values)[0]),
                'values': [v*ts_names_map[name][1] for v in list(zip(*values)[1])],
                'priority': 10
            }

    # The time series data is only included if it is present.
    if time_series:
        job['time_series'] = time_series

    return job


if __name__ == "__main__":

    # Parser for the required arguments
    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("path_run", type=str, help="Path of the kronos run folder (contains the job-<ID> sub-folders)")
    parser.add_argument("kpf_file", type=str, help="Name of the KPF file to write out")

    # print the help if no arguments are passed
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    # parse the arguments..
    args = parser.parse_args()

    if not os.path.exists(args.path_run):
        print "Specified run path does not exist: {}".format(args.path_run)
        sys.exit(-1)

    if os.path.exists(args.kpf_file):
        print "Output KPF file {} already exists!".format(args.kpf_file)
        sys.exit(-1)

    # path of the output kpf file
    path_kpf = os.path.dirname(os.path.abspath(args.kpf_file))
    if not os.path.exists(path_kpf):
        os.mkdir(path_kpf)

    # ---------- Process the run jsons ----------
    print "writing output kpf file: {}".format(args.kpf_file)
    job_dirs = [x for x in os.listdir(args.path_run) if os.path.isdir(os.path.join(args.path_run, x)) and "job-" in x]

    job_json_all = []
    for job_dir in job_dirs:

        sub_dir_path_abs = os.path.join(args.path_run, job_dir)
        sub_dir_files = os.listdir(sub_dir_path_abs)
        krf_file = [f for f in sub_dir_files if f.endswith('.krf')]

        print krf_file

        if krf_file:

            krf_file_name = krf_file[0]
            krf_file_full = os.path.join(sub_dir_path_abs, krf_file_name)
            krf_base_abs = os.path.splitext(krf_file_full)[0]
            print "processing KRF file: {}".format(krf_file_full)

            input_file_path_abs = os.path.join(sub_dir_path_abs, 'input.json')

            # read the corresponding json of the input and read the label
            with open(input_file_path_abs, 'r') as f:
                input_data_json = json.load(f)

            label = input_data_json['metadata']['workload_name']
            job_ID = input_data_json['job_num']

            krf_data_json = ResultsFormat.from_filename(krf_file_full).output_dict()

            # fill up the json data of the job (from statistics and input file)
            job_json = krf_to_profiled_job_json(krf_data_json, input_data_json)

            # append to list
            if job_json:
                job_json_all.append(job_json)

    # Build the data structure for the KPF file format
    pf = ProfileFormat(json_jobs=job_json_all, workload_tag='kronos_workload')

    # write output kpf file..
    with open(args.kpf_file, 'w') as f:
        pf.write(f)
