#!/usr/bin/env python
# (C) Copyright 1996-2017 ECMWF.
#
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.
# In applying this licence, ECMWF does not waive the privileges and immunities
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""
script to generate a summary from the KRF files in the run folder
"""

import os
import json
import argparse
import sys

if __name__ == "__main__":

    # Parser for the required arguments
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("path_run", type=str, help="Path of the kronos run folder (contains the job-<ID> sub-folders)")
    args = parser.parse_args()

    if not os.path.exists(args.path_run):
        print "Specified run path does not exist: {}".format(args.path_run)
        sys.exit(-1)

    job_dirs = [x for x in os.listdir(args.path_run) if os.path.isdir(os.path.join(args.path_run, x)) and "job-" in x]

    if not job_dirs:
        print "Specified path does not contain any job folder (<job-ID>..)!"
        sys.exit(-1)

    fname_list = []
    dict_name_label = {}

    jobs_data_dict = {}
    for job_dir in job_dirs:

        sub_dir_path_abs = os.path.join(args.path_run, job_dir)
        sub_dir_files = os.listdir(sub_dir_path_abs)
        krf_file = [f for f in sub_dir_files if f.endswith('.krf')]

        if krf_file:

            map_file_name = krf_file[0]
            map_file_full = os.path.join(sub_dir_path_abs, map_file_name)
            map_base_abs = os.path.splitext(map_file_full)[0]

            input_file_path_abs = os.path.join(sub_dir_path_abs, 'input.json')
            stats_file_path_abs = os.path.join(sub_dir_path_abs, 'statistics.krf')

            # read input file
            with open(input_file_path_abs, 'r') as f:
                json_data_input = json.load(f)

            # read stats file
            with open(stats_file_path_abs, 'r') as f:
                json_data_stats = json.load(f)

            # transfer data from input file to stats file
            json_data_stats['metadata'] = json_data_input['metadata']

            if json_data_input['metadata'].get('workload_name'):
                jobs_data_dict.setdefault(json_data_input['metadata']['workload_name'], []).append(json_data_stats)

    # print summary
    print "{:<52s}".format("\n\nPERFORMANCE SUMMARY:")

    for wl_name in jobs_data_dict.keys():

        jobs_in_wl = jobs_data_dict[wl_name]

        # -------- calculate relevant summary measures as needed.. ---------
        data_keys = {
            "cpu": {"label": "GFLOPS/sec", "conv": 1.0/1024**3},
            "read": {"label": "I/O read: [G/s]", "conv": 1.0/1024**3},
            "write": {"label": "I/O write: [G/s]", "conv": 1.0/1024**3},
            "mpi-pairwise": {"label": "MPI p2p: [G/s]", "conv": 1.0/1024**3},
            "mpi-collective": {"label": "MPI col: [G/s]", "conv": 1.0/1024**3}
        }

        perf_data = {}
        for name in data_keys.keys():
            perf_data[name] = [(rank["stats"][name]["count"],
                                rank["stats"][name]["bytes"] if name != "cpu" else 0.0,
                                rank["stats"][name]["elapsed"])
                               for sa in jobs_in_wl for rank in sa["ranks"] if rank["stats"].get(name)]
        # ------------------------------------------------------------------------------------------------

        summary_data = {}
        for k in data_keys.keys():
            summary_data[k] = {"vec": zip(*perf_data[k])}

        for k in summary_data.keys():

            if not summary_data[k]["vec"]:

                summary_data[k]["mean"] = "N/A"
                summary_data[k]["max"] = "N/A"
                summary_data[k]["min"] = "N/A"
                summary_data[k]["std"] = "N/A"

            else:
                # counter per sec
                if k == "cpu":

                    sc = data_keys[k]["conv"]
                    vals = [f0/float(f2)*sc for f0, f2 in zip(summary_data[k]["vec"][0], summary_data[k]["vec"][2])]
                    mean_val = sum(vals)/float(len(vals))
                    summary_data[k]["mean"] = mean_val
                    summary_data[k]["max"] = max(vals)
                    summary_data[k]["min"] = min(vals)
                    summary_data[k]["std"] = (sum([(v-mean_val)**2 for v in vals])/float(len(vals)))**0.5

                # bytes per sec..
                else:

                    sc = data_keys[k]["conv"]
                    vals = [f1 / float(f2) * sc for f1, f2 in zip(summary_data[k]["vec"][1], summary_data[k]["vec"][2])]
                    mean_val = sum(vals) / float(len(vals))
                    summary_data[k]["mean"] = mean_val
                    summary_data[k]["max"] = max(vals)
                    summary_data[k]["min"] = min(vals)
                    summary_data[k]["std"] = (sum([(v - mean_val) ** 2 for v in vals]) / float(len(vals)) ) ** 0.5

        _fl = 20
        print "\n\n{}".format("-"*(_fl+1)*5)
        print "{:^{l}s}|".format(wl_name, l=(_fl + 1) * 5-1)
        print "{}".format("-"*(_fl+1)*5)
        print "{:<{l}s}|{:^{l}s}|{:^{l}s}|{:^{l}s}|{:^{l}s}|".format("Name",
                                                                     "avg",
                                                                     "max",
                                                                     "min",
                                                                     "std",
                                                                     "latency (est)",
                                                                     "bandwidth (est)",
                                                                     l=_fl)
        print "{}".format("-"*(_fl+1)*5)

        for k in summary_data.keys():
            if isinstance(summary_data[k]["mean"], str):
                print "{:<{l}s}|{:>{l}}|{:>{l}}|{:>{l}}|{:>{l}}|".format(data_keys[k]["label"],
                                                                         summary_data[k]["mean"],
                                                                         summary_data[k]["max"],
                                                                         summary_data[k]["min"],
                                                                         summary_data[k]["std"],
                                                                         l=_fl)
            else:
                print "{:<{l}s}|{:>{l}f}|{:>{l}f}|{:>{l}f}|{:>{l}f}|".format(data_keys[k]["label"],
                                                                             summary_data[k]["mean"],
                                                                             summary_data[k]["max"],
                                                                             summary_data[k]["min"],
                                                                             summary_data[k]["std"],
                                                                             l=_fl)
        print "{}".format("-" * (_fl + 1) * 5)

