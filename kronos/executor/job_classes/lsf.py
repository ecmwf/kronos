from kronos.executor.job_classes.hpc import HPCJob

#####################################################################################################
# This file is an example of a job submit template needed to run the executor on a HPC system. This template is
# called "lsf.py" and is an example template that can be used to submit jobs to a LSF scheduler. In order to
# instruct the executor to use this template, the following entry should be set in the executor configuration file:
#
# - "job_class": "lsf"
#
# Below, the details of how to setup the script are provided. This script can also be used as reference to generate user
# defined submit scripts (e.g. "user_job_script.py") that will then be invoked by setting the following entry in the
# executor config file:
#
# - "job_class": "user_job_script"
#
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Template fields automatically set by Kronos
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# 1) This section briefly describes the fields that are used by Kronos Executor to automatically populate
#    the template below ("submit_script_template"). The rest of the template needs to be adapted to the host HPC system
#    and scheduler as appropriate
#
#     experiment_id: "job-ID"
#
#     num_nodes: "Number of nodes requested from the system. The Executor requests a number of nodes that is
#                 equal to N_processes (as specified in the KSF for each synthetic app) divided by the
#                 number of processors per node as specified in the executor config file"
#
#     num_procs: "Number of MPI ranks requested
#
#     job_output_file: "job stdout file in the job folder"
#
#     job_error_file: "job error file in the job folder"
#
#     write_dir: "executor output folder"
#
#     read_dir: "folder containing the read files - automatically generated by Kronos before the run"
#
#     shared_dir: "auxiliary folder used for operations that the synthetic apps might perform on a shared folder
#                 like mkdir/rmdir (only used if these types of operations are present in the KSF file)"
#
#     job_dir: "job output directory"
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Variables to be manually set by the user
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# 2) In addition to the main template of the submit scripts, the following variables need to be MANUALLY set
#    in the template class below
#
#    submit_command: "The command used to submit jobs to the scheduler (e.g. "qsub" for PBS)"
#
#    depend_parameter: "The argument used to specify job dependencies to the scheduler on the command line.
#                      (e.g. "-W depend=afterany:" for PBS)."
#
#    depend_separator = "separator used when constructing the job dependency list for submission to the
#                       scheduler (e.g. for lsf use ":")"
#
#    launcher_command: "Command to begin the parallel part of the job (e.g. "aprun" for PBS on cray systems)"
#
#    cancel_file_head: "header of the "killjobs" bash script that Kronos automatically generates in the output folder"
#
#    cancel_file_line: "this is the list of job IDs that will be killed by the the killjobs script is invoked"
#
#                      - NB: the variable "sequence_id" with the list of job ID's is provided by Kronos
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Other Variables
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# The following variables can also be specified if the synthetic apps are to be profiled,
# but their usage is momentarily *unsupported*:
# ipm_template: IPM code
# darshan_template: Darshan code
# allinea_template, allinea_lic_file_template: Allinea MAP code
#
#####################################################################################################


job_template = """#!/bin/bash
#BSUB -L /bin/bash
#BSUB -J {experiment_id}
#BSUB -q {queue}
#BSUB -n {num_procs}
#BSUB -R "affinity[thread(2):cpubind=thread:distribute=pack] span[ptile=80] select[hname==p10a32 || hname==p10a47 || hname==p10a35 || hname==p10a38 || hname==p10a26 || hname==p10a44 || hname==p10a30 || hname==p10a46 || hname=p10a42 || hname==p10a43 || hname==p10a45 || hname==p10a52]"
#BSUB -o {job_output_file}
#BSUB -e {job_error_file}
#BSUB -H

# Configure the locations for the synthetic app to dump/load files in the i/o kernels
export KRONOS_WRITE_DIR="{write_dir}"
export KRONOS_READ_DIR="{read_dir}"
export KRONOS_SHARED_DIR="{shared_dir}"

export LD_LIBRARY_PATH={coordinator_library_path}:${{LD_LIBRARY_PATH}}

# Change to the original directory for submission
cd {job_dir}

# Export an EC experiment ID (to assist identifying the job in darshan logs)
export EC_experiment_id="{experiment_id}"

{profiling_code}

{launcher_command} -x LD_LIBRARY_PATH="${{LD_LIBRARY_PATH}}" -N {procs_per_node} -n {num_procs} {coordinator_binary} {input_file}
"""


ipm_template = """
# Configure IPM
module load ipm
export IPM_LOGDIR={job_dir}/ipm-logs
export IPM_HPM=PAPI_FP_OPS,PAPI_TOT_INS,PAPI_L1_DCM,PAPI_L2_DCM,PAPI_L3_DCM,PAPI_L1_DCA,PAPI_L1_TCM,PAPI_L2_TCM,PAPI_L3_TCM
"""

darshan_template = """
export DARSHAN_LOG_PATH={job_dir}
export LD_PRELOAD={darshan_lib_path}
"""

allinea_template = """
# Configure Allinea Map
export PATH={allinea_path}:${{PATH}}
export LD_LIBRARY_PATH={allinea_ld_library_path}:${{LD_LIBRARY_PATH}}
"""

allinea_lic_file_template = """
export ALLINEA_LICENCE_FILE={allinea_licence_file}
"""

cancel_file_head = "#!/bin/sh\nbkill "
cancel_file_line = "{sequence_id} "


class LSFMixin(object):
    """
    Define the templates for LSF
    """

    submit_script_template = job_template
    ipm_template = ipm_template
    darshan_template = darshan_template
    allinea_template = allinea_template
    submit_command = "lsf_filter.sh"
    depend_parameter = "-w "
    depend_separator = ":"
    launcher_command = 'mpiexec'
    allinea_launcher_command = "map --profile aprun"
    allinea_lic_file_template = allinea_lic_file_template
    cancel_file_head = cancel_file_head
    cancel_file_line = cancel_file_line


class Job(LSFMixin, HPCJob):
    pass

