from kronos.executor.job_classes.hpc import HPCJob

#####################################################################################################
# This file is an example of a job submit template needed to run the executor on a HPC system. This template is
# called "pbs.py" and can be used to submit jobs to a PBS scheduler.
#
# NOTE: The scheduler configurations need to be adapted to the specific system that kronos is going to be run on
# For example, the "EC_<>" options below refer to specific settings for the ECMWF scheduler system and
# are not relevant/applicable to any other system)
#
# In order to instruct the executor to use this template, the following entry should be set in the executor
# configuration file:
#
# - "job_class": "pbs"
#
# Below, the details of how to setup the script are provided. This script can also be used as reference to generate user
# defined submit scripts (e.g. "user_job_script.py") that will then be invoked by setting the following entry in the
# executor config file:
#
# - "job_class": "user_job_script"
#
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Template fields automatically set by Kronos
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# 1) This section briefly describes the fields that are used by Kronos Executor to automatically populate
#    the template below ("submit_script_template"). The rest of the template needs to be adapted to the host HPC system
#    and scheduler as appropriate
#
#     experiment_id: "job-ID"
#
#     num_nodes: "Number of nodes requested from the system. The Executor requests a number of nodes that is
#                 equal to N_processes (as specified in the KSchedule for each synthetic app) divided by the
#                 number of processors per node as specified in the executor config file"
#
#     num_procs: "Number of MPI ranks requested
#
#     job_output_file: "job stdout file in the job folder"
#
#     job_error_file: "job error file in the job folder"
#
#     write_dir: "executor output folder"
#
#     read_dir: "folder containing the read files - automatically generated by Kronos before the run"
#
#     shared_dir: "auxiliary folder used for operations that the synthetic apps might perform on a shared folder
#                 like mkdir/rmdir (only used if these types of operations are present in the KSchedule file)"
#
#     job_dir: "job output directory"
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Variables to be manually set by the user
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# 2) In addition to the main template of the submit scripts, the following variables need to be MANUALLY set
#    in the template class below
#
#    submit_command: "The command used to submit jobs to the scheduler (e.g. "qsub" for PBS)"
#
#    depend_parameter: "The argument used to specify job dependencies to the scheduler on the command line.
#                      (e.g. "-W depend=afterany:" for PBS)."
#
#    depend_separator = "separator used when constructing the job dependency list for submission to the
#                       scheduler (e.g. for pbs use ":")"
#
#    launcher_command: "Command to begin the parallel part of the job (e.g. "aprun" for PBS on cray systems)"
#
#    cancel_file_head: "header of the "killjobs" bash script that Kronos automatically generates in the output folder"
#
#    cancel_file_line: "this is the list of job IDs that will be killed by the the killjobs script is invoked"
#
#                      - NB: the variable "sequence_id" with the list of job ID's is provided by Kronos
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Other Variables
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# The following variables can also be specified if the synthetic apps are to be profiled,
# but their usage is momentarily *unsupported*:
# ipm_template: IPM code
# darshan_template: Darshan code
# allinea_template, allinea_lic_file_template: Allinea MAP code
#
#####################################################################################################


job_template = """#!/bin/sh
#PBS -N {experiment_id}
#PBS -q np
#PBS -l EC_nodes={num_nodes}
#PBS -l EC_total_tasks={num_procs}
#PBS -l EC_threads_per_task=1
#PBS -l EC_hyperthreads={num_hyperthreads}
#PBS -o {job_output_file}
#PBS -e {job_error_file}

# Configure the locations for the synthetic app to dump/load files in the i/o kernels
export KRONOS_WRITE_DIR="{write_dir}"
export KRONOS_READ_DIR="{read_dir}"
export KRONOS_SHARED_DIR="{shared_dir}"
export KRONOS_TOKEN="{simulation_token}"

export LD_LIBRARY_PATH={coordinator_library_path}:${{LD_LIBRARY_PATH}}

# Change to the original directory for submission
cd {job_dir}

# Export an EC experiment ID (to assist identifying the job in darshan logs)
export EC_experiment_id="{experiment_id}"

{profiling_code}

{launcher_command} -e LD_LIBRARY_PATH="${{LD_LIBRARY_PATH}}" -N {procs_per_node} -n {num_procs} {coordinator_binary} {input_file}
"""


ipm_template = """
# Configure IPM
module load ipm
export IPM_LOGDIR={job_dir}/ipm-logs
export IPM_HPM=PAPI_FP_OPS,PAPI_TOT_INS,PAPI_L1_DCM,PAPI_L2_DCM,PAPI_L3_DCM,PAPI_L1_DCA,PAPI_L1_TCM,PAPI_L2_TCM,PAPI_L3_TCM
"""

darshan_template = """
export DARSHAN_LOG_PATH={job_dir}
export LD_PRELOAD={darshan_lib_path}
"""

allinea_template = """
# Configure Allinea Map
export PATH={allinea_path}:${{PATH}}
export LD_LIBRARY_PATH={allinea_ld_library_path}:${{LD_LIBRARY_PATH}}
"""

allinea_lic_file_template = """
export ALLINEA_LICENCE_FILE={allinea_licence_file}
"""

cancel_file_head = "#!/bin/sh\nqdel "
cancel_file_line = "{sequence_id} "


class PBSMixin(object):
    """
    Define the templates for PBS
    """

    submit_script_template = job_template
    ipm_template = ipm_template
    darshan_template = darshan_template
    allinea_template = allinea_template
    submit_command = "qsub"
    depend_parameter = "-W depend=afterany:"
    depend_separator = ":"
    launcher_command = 'aprun'
    allinea_launcher_command = "map --profile aprun"
    allinea_lic_file_template = allinea_lic_file_template
    cancel_file_head = cancel_file_head
    cancel_file_line = cancel_file_line


class Job(PBSMixin, HPCJob):
    pass

