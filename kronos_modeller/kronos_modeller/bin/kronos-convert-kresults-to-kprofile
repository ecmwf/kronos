#!/usr/bin/env python
# (C) Copyright 1996-2018 ECMWF.
#
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.
# In applying this licence, ECMWF does not waive the privileges and immunities
# granted to it by virtue of its status as an intergovernmental organisation nor
# does it submit to any jurisdiction.

"""

Utility script to go through the kronos run folder and generates a KProfile
from the statistics.kresults files.

Note: by doing this some information is lost! In fact, kresults format contains "per-process"
information, while kprofile format aggregates information per-job.

Limitation: this tool only collects statistics for the jobs that produce a kresults file.

"""

import os
import sys
import json
import argparse
import numpy as np

from kronos_executor.io_formats.definitions import kresults_ts_names_map
from kronos_executor.io_formats.profile_format import ProfileFormat
from kronos_executor.io_formats.results_format import ResultsFormat


def kresults_to_profiled_job_json(kresults_json, input_json):
    """
    Function that reads statistics.kresults and input.json and builds job json data
    (to be later used for ProfileFormat)
    :param kresults_json:
    :param input_json:
    :return:
    """

    job = {}

    # create time series json data from statistics.kresults
    time_series_json = {}

    for rank_data in kresults_json["ranks"]:

        tends = np.cumsum(rank_data["time_series"]['durations'])

        if not rank_data["time_series"]['durations']:
            # in case the durations are empty!
            return None

        for ts_name, ts_vals in rank_data["time_series"].iteritems():

            if ts_name != "durations":
                time_series_json.setdefault(ts_name, []).extend(zip(tends, ts_vals))

    # sort the time-series
    for ts in time_series_json.values():
        ts.sort(key=lambda _x: _x[0])

    # time delay of job submission
    if input_json.get("start_delay"):
        job['time_start'] = input_json.get("start_delay")

    # job runtime
    job['duration'] = max([v[0] for ts in time_series_json.values() for v in ts])

    if input_json.get("start_delay"):
        job['ncpus'] = input_json.get("num_procs")

    if input_json.get("metadata"):
        job['label'] = input_json["metadata"]["workload_name"]

    if input_json.get("metadata"):
        job['job_name'] = input_json["metadata"]["job_name"]

    # Append any time series data that is present
    time_series = {}
    for name, values in time_series_json.iteritems():

        # assert name in time_signal.signal_types
        assert name in kresults_ts_names_map.keys()

        if values is not None:
            time_series[kresults_ts_names_map[name][0]] = {
                'times': list(zip(*values)[0]),
                'values': [v * kresults_ts_names_map[name][1] for v in list(zip(*values)[1])],
                'priority': 10
            }

    # The time series data is only included if it is present.
    if time_series:
        job['time_series'] = time_series

    return job


if __name__ == "__main__":

    # Parser for the required arguments
    parser = argparse.ArgumentParser(description=__doc__,
                                     formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument("path_run", type=str, help="Path of the kronos run folder "
                                                   "(contains the job-<ID> sub-folders)")

    parser.add_argument("kprofile_file", type=str, help="Name of the KProfile file to write out")

    # print the help if no arguments are passed
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    # parse the arguments..
    args = parser.parse_args()

    if not os.path.exists(args.path_run):
        print "Specified run path does not exist: {}".format(args.path_run)
        sys.exit(1)

    if os.path.exists(args.kprofile_file):
        print "Output KProfile file {} already exists!".format(args.kprofile_file)
        sys.exit(1)

    # path of the output kprofile file
    path_kprofile = os.path.dirname(os.path.abspath(args.kprofile_file))
    if not os.path.exists(path_kprofile):
        os.mkdir(path_kprofile)

    # ---------- Process the run jsons ----------
    print "writing output kprofile file: {}".format(args.kprofile_file)
    job_dirs = [x for x in os.listdir(args.path_run)
                if os.path.isdir(os.path.join(args.path_run, x)) and "job-" in x]

    job_json_all = []
    for job_dir in job_dirs:

        sub_dir_path_abs = os.path.join(args.path_run, job_dir)
        sub_dir_files = os.listdir(sub_dir_path_abs)
        kresults_file = [f for f in sub_dir_files if f.endswith('.kresults')]

        print kresults_file

        if kresults_file:

            kresults_file_name = kresults_file[0]
            kresults_file_full = os.path.join(sub_dir_path_abs, kresults_file_name)
            kresults_base_abs = os.path.splitext(kresults_file_full)[0]
            print "processing KResults file: {}".format(kresults_file_full)

            input_file_path_abs = os.path.join(sub_dir_path_abs, 'input.json')

            # read the corresponding json of the input and read the label
            with open(input_file_path_abs, 'r') as f:
                input_data_json = json.load(f)

            label = input_data_json['metadata']['workload_name']
            job_ID = input_data_json['job_num']

            kresults_data_json = ResultsFormat.from_filename(kresults_file_full).output_dict()

            # fill up the json data of the job (from statistics and input file)
            job_json = kresults_to_profiled_job_json(kresults_data_json, input_data_json)

            # append to list
            if job_json:
                job_json_all.append(job_json)

    # Build the data structure for the KProfile file format
    pf = ProfileFormat(json_jobs=job_json_all, workload_tag='kronos_workload')

    # write output kprofile file..
    with open(args.kprofile_file, 'w') as f:
        pf.write(f)
